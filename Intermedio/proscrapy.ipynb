{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spider12(scrapy.Spider):\n",
    "    name = 'spider12'\n",
    "    # dominios a scrapear\n",
    "    allowed_domains = ['pagina12.com.ar']  \n",
    "    # formato de archivo de salida\n",
    "    custom_settings = {'FEED_FORMAT':'json',   \n",
    "                       'FEED_URI': 'resultados.json',\n",
    "                       'DEPTH_LIMIT': 2}  \n",
    "    \n",
    "    # URLS a scrapear\n",
    "    starts_urls = ['https://www.pagina12.com.ar/secciones/el-pais',\n",
    "                  'https://www.pagina12.com.ar/secciones/economia',\n",
    "                  'https://www.pagina12.com.ar/secciones/sociedad',\n",
    "                  'https://www.pagina12.com.ar/suplementos/cultura-y-espectaculos',\n",
    "                  'https://www.pagina12.com.ar/secciones/el-mundo',\n",
    "                  'https://www.pagina12.com.ar/secciones/deportes',\n",
    "                  'https://www.pagina12.com.ar/secciones/contratapa',\n",
    "                  'https://www.pagina12.com.ar/secciones/audiovisuales']\n",
    "    \n",
    "    # Procesar la respuesta de cada solicitud\n",
    "    def parse(self, response):\n",
    "        \n",
    "        # Articulo promocionado\n",
    "        nota_promocionada = response.xpath('//div[@class=\"featured-article__container\"]/h2/a/@href').get()\n",
    "        if nota_promocionada is not None:\n",
    "            # Pasar la respuesta a parse_nota\n",
    "            yield response.follow(nota_promocionada, callback=self.parse_nota)\n",
    "        \n",
    "        # Listado de notas\n",
    "        notas = response.path('//ul[@class=\"article-list\"]//li//a/@href').getall()\n",
    "        for nota in notas: \n",
    "            # Pasar la respuesta a parse_nota\n",
    "            yield response.follow(nota, callback=self.parse_nota)\n",
    "        \n",
    "        \n",
    "    def parse_nota(self, response):\n",
    "        date = response.xpath('//div[@class=\"time\"]/span/@datetime').get()\n",
    "        prefix = response.xpath('//h2[@class=\"article-prefix\"]/text()').get()\n",
    "        title = response.xpath('//h1[@class=\"article-titles\"]/text()').get()\n",
    "        summary = response.xpath('//div[@class=\"article-summary\"]/text()').get()\n",
    "        content = response.xpath('//div[@class=\"article-text\"]/text()').getall()\n",
    "        image = response.xpath('//div[@class=\"article-main-media-image__container\"]/img/@src').getall()[-1] \n",
    "        yield {'url': response.url,\n",
    "                'title':title,\n",
    "                'cuerpo':cuerpo,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess()\n",
    "process.crawl(Spider12)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
